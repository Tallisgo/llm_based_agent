{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the `ask` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in d:\\app\\anaconda\\anaconda3\\envs\\agent\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
      "   ---------------------------------------- 0.0/337.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/337.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 81.9/337.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 194.6/337.0 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 317.4/337.0 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 337.0/337.0 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-1.37.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "\n",
    "def ask(messages: List[Dict]):\n",
    "        #需要指定api key 以及base_url\n",
    "        client = OpenAI(api_key='sk-6300ae0b0cd0431492e8c1f8ade630ba', base_url=\"https://api.deepseek.com\")\n",
    "        response = client.chat.completions.create(\n",
    "                model = 'deepseek-chat',\n",
    "                temperature = 0,\n",
    "                messages = messages\n",
    "        )\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find out how many apples the cafeteria has now, we need to follow these steps:\n",
      "\n",
      "1. Start with the initial number of apples, which is 23.\n",
      "2. Subtract the number of apples used to make lunch, which is 20.\n",
      "3. Add the number of apples bought, which is 6.\n",
      "\n",
      "Let's do the calculations step by step:\n",
      "\n",
      "1. Initial number of apples: 23\n",
      "2. Subtract the apples used: 23 - 20 = 3\n",
      "3. Add the apples bought: 3 + 6 = 9\n",
      "\n",
      "So, the cafeteria now has 9 apples.\n"
     ]
    }
   ],
   "source": [
    "# 给LLM一个 role\n",
    "system_prompt = \"You are a helpful assistant\" \n",
    "\n",
    "question = \"\"\"\n",
    "Q: The cafeteria had 23 apples.\n",
    "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "A:\"\"\"\n",
    "\n",
    "# 对输入的 messages 进行处理，以满足 LLM 对输入的要求\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":system_prompt},\n",
    "    {\"role\":\"user\", \"content\":question},\n",
    "]\n",
    "\n",
    "\n",
    "response = ask(messages)\n",
    "\n",
    "# 后处理返回的结果\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The cafeteria started with 23 apples. They used 20 for lunch, so they had 23 - 20 = 3 apples left. Then they bought 6 more apples, so the total number of apples they have now is 3 + 6 = 9. The answer is 9.\n"
     ]
    }
   ],
   "source": [
    "# 给LLM一个 role\n",
    "system_prompt = \"You are a helpful assistant\" \n",
    "\n",
    "question = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls\n",
    "each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "Q: The cafeteria had 23 apples.\n",
    "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "\"\"\"\n",
    "\n",
    "# 对输入的 messages 进行处理，以满足 LLM 对输入的要求\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":system_prompt},\n",
    "    {\"role\":\"user\", \"content\":question},\n",
    "]\n",
    "\n",
    "\n",
    "response = ask(messages)\n",
    "\n",
    "# 后处理返回的结果\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give a sample to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The answer is 9.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant\" # 给LLM一个 role\n",
    "\n",
    "question = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: The answer is 11.\n",
    "Q: The cafeteria had 23 apples.\n",
    "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "A:\"\"\"\n",
    "\n",
    "# 对输入的 messages 进行处理，以满足 LLM 对输入的要求\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":system_prompt},\n",
    "    {\"role\":\"user\", \"content\":question},\n",
    "]\n",
    "\n",
    "\n",
    "response = ask(messages)\n",
    "\n",
    "# 后处理返回的结果\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use magic word\n",
    "\n",
    "`Let's think step by step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Let's think step by step.\n",
      "\n",
      "1. The cafeteria initially had 23 apples.\n",
      "2. They used 20 apples to make lunch, so they had 23 - 20 = 3 apples left.\n",
      "3. They bought 6 more apples, so the total number of apples they have now is 3 + 6 = 9 apples.\n",
      "\n",
      "So, the answer is 9.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: The answer is 11.\n",
    "\n",
    "Q: The cafeteria had 23 apples.\n",
    "If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "A: Let's think step by step.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":system_prompt},\n",
    "    {\"role\":\"user\", \"content\":question},\n",
    "]\n",
    "\n",
    "\n",
    "results = ask(messages)\n",
    "\n",
    "print(results.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf9bbd8761e205a067c272e6ed0abbdf91f38ae4d8d5f3f65ae82c28409ae2c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
